# ğŸ® Predictive Analysis of Game Success in STEAM Using Interpretable AI

ğŸ“Š Applied Artificial Intelligence Coursework
ğŸ‘¨â€ğŸ’» Author: Tharindu D. Mallawaarachchi


---

## ğŸ“Œ Project Overview

The STEAM marketplace contains thousands of games, but predicting commercial success remains highly uncertain.

This project builds a **machine learning classification system** to predict whether a game will be successful based on structured metadata â€” while ensuring transparency using **Interpretable AI techniques**.

Instead of relying on black-box predictions, this study integrates **SHAP (SHapley Additive exPlanations)** to explain:

â€¢ Why the model made a prediction
â€¢ Which features contribute most to success
â€¢ How different attributes influence outcomes

The goal is not only prediction accuracy â€” but meaningful insight.

---

## ğŸ¯ Objectives

âœ” Predict game success using machine learning
âœ” Apply structured preprocessing and feature engineering
âœ” Evaluate performance using classification metrics
âœ” Integrate SHAP for model interpretability
âœ” Provide transparent insights into key success factors

---

## ğŸ“‚ Dataset

The dataset includes STEAM game metadata such as:

â€¢ Number of user reviews
â€¢ Rating percentage
â€¢ Price
â€¢ Genre information
â€¢ Release data
â€¢ Other structured features

### Data Preparation Steps

ğŸ§¹ Removed invalid and zero-recommendation entries
ğŸ”„ Handled missing values
ğŸ”¢ Encoded categorical variables
ğŸ“ Normalized / scaled numerical features
âœ‚ Split into training and testing sets

---

## ğŸ§  Model Architecture

The project uses:

ğŸŒ³ Random Forest Classifier

Why Random Forest?

â€¢ Handles non-linear relationships well
â€¢ Robust to noise
â€¢ Strong performance on tabular datasets
â€¢ Provides built-in feature importance

---

## ğŸ“ˆ Model Evaluation

Performance is evaluated using:

â€¢ Accuracy
â€¢ Precision
â€¢ Recall
â€¢ F1-score
â€¢ Confusion Matrix

This ensures balanced evaluation beyond simple accuracy.

---

## ğŸ” Interpretable AI Layer

To prevent black-box decisions, SHAP analysis is applied:

ğŸ“Š Global Feature Importance
ğŸ“Œ Individual Prediction Explanations
ğŸ“ˆ SHAP Summary Visualization

This allows us to understand *why* a game is predicted as successful.

Prediction without explanation is guessing with math.
Prediction with explanation is insight.

---

## ğŸš€ How to Run the Project

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/YOUR_USERNAME/Predictive-Analysis-of-Game-Success-in-STEAM-Using-Interpretable-AI.git
cd Predictive-Analysis-of-Game-Success-in-STEAM-Using-Interpretable-AI
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run Notebook

```bash
jupyter notebook
```

Open:

`STEAM Game Sucess Predictor.ipynb`

---

## ğŸ§ª Quick Prototype Test

To quickly test the trained model:

Inside the notebook, locate the prediction section and run:

```python
sample_input = X_test.iloc[[0]]
model.predict(sample_input)
```

This generates a success prediction for a sample game.

To view explanation:

```python
shap_values = explainer(sample_input)
shap.plots.waterfall(shap_values[0])
```

This shows exactly which features influenced the prediction.

---

## ğŸ—‚ Repository Structure

```
ğŸ“ Predictive-Analysis-of-Game-Success-in-STEAM-Using-Interpretable-AI
â”‚
â”œâ”€â”€ ğŸ““ STEAM Game Sucess Predictor.ipynb
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“„ requirements.txt
â””â”€â”€ ğŸ“ assets (optional â€“ saved plots)
```

---

## ğŸ›  Technologies Used

ğŸ Python
ğŸ“Š Pandas
ğŸ”¢ NumPy
ğŸ¤– Scikit-learn
ğŸ” SHAP
ğŸ“ˆ Matplotlib
ğŸ“‰ Seaborn
ğŸ““ Jupyter Notebook

---

## ğŸ’¡ Key Insights

The analysis shows that:

â€¢ Review volume strongly impacts predicted success
â€¢ Rating percentage is a dominant predictor
â€¢ Pricing influences performance patterns
â€¢ Certain categorical features contribute meaningfully

SHAP confirms these relationships quantitatively.

---

## ğŸ”® Future Improvements

ğŸŒ Deploy as a web-based dashboard
ğŸ“¡ Integrate live STEAM API data
ğŸ“Š Compare multiple ensemble models
ğŸ“ˆ Add temporal trend modeling
ğŸ§  Explore causal inference approaches

---

## ğŸ“œ Academic Context

This project was developed as part of an Applied Artificial Intelligence coursework module.

It demonstrates:

âœ” Data preprocessing rigor
âœ” Model justification
âœ” Evaluation methodology
âœ” Interpretability integration
âœ” Analytical discussion of results

---

Now â€” letâ€™s elevate this further.

To make your repository even stronger:

1ï¸âƒ£ Export your confusion matrix as PNG
2ï¸âƒ£ Export SHAP summary plot as PNG
3ï¸âƒ£ Add them inside an `assets/` folder
4ï¸âƒ£ Embed in README using:

```markdown
![Confusion Matrix](assets/confusion_matrix.png)
![SHAP Summary](assets/shap_summary.png)
```

This transforms it from â€œstudent uploadâ€ to â€œAI portfolio projectâ€.

